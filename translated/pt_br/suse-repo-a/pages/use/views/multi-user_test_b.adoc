= Configuração de vários usuários
:revdate: 2025-04-30
:page-revdate: {revdate}

{product_name} usa o Kubernetes RBAC sempre que possível.

Uma adição ao RBAC é o recurso xref:explanations/namespaces.adoc#_restricting_gitrepos[`+GitRepoRestriction+`] que pode ser usado para controlar os recursos do GitRepo em um namespace.

Uma configuração de frota multiusuário tem a seguinte aparência:

* os locatários não compartilham namespaces, cada locatário tem um ou mais namespaces no cluster upstream, onde podem criar recursos do GitRepo
* os locatários não podem implementar recursos em todo o cluster e estão limitados a um conjunto de namespaces em clusters downstream
* os clusters estão em um namespace separado

image::FleetSharedClusters.svg[Clusters compartilhados]

[CAUTION]
.Informações importantes
====

O isolamento dos locatários não é completo e depende do Kubernetes RBAC para ser configurado corretamente. Sem a configuração manual de um operador, os locatários ainda podem implementar recursos em todo o cluster. Mesmo com as restrições disponíveis no site {product_name}, os usuários estão restritos apenas aos namespaces, mas os namespaces não oferecem muito isolamento por si só. Por exemplo, eles ainda podem consumir quantos recursos quiserem.

No entanto, as restrições existentes no site {product_name} permitem que os usuários compartilhem clusters e implementem recursos sem conflitos.
====


== Exemplo {product_name} Standalone

Isso criaria um usuário "fleetuser", que só pode gerenciar recursos do GitRepo no namespace "project1".

[,bash]
----
 kubectl create serviceaccount fleetuser
 kubectl create namespace project1
 kubectl create -n project1 role fleetuser --verb=get --verb=list --verb=create --verb=delete --resource=gitrepos.fleet.cattle.io
 kubectl create -n project1 rolebinding fleetuser --serviceaccount=default:fleetuser --role=fleetuser
----

Se quisermos dar acesso a vários namespaces, poderemos usar uma única função de cluster com duas associações de funções:

[,bash]
----
 kubectl create clusterrole fleetuser --verb=get --verb=list --verb=create --verb=delete --resource=gitrepos.fleet.cattle.io
 kubectl create -n project1 rolebinding fleetuser --serviceaccount=default:fleetuser --clusterrole=fleetuser
 kubectl create -n project2 rolebinding fleetuser --serviceaccount=default:fleetuser --clusterrole=fleetuser
----

Isso garante que os locatários não possam interferir nos recursos do GitRepo de outros locatários, já que eles não têm acesso a seus namespaces.

== Exemplo {product_name} no Rancher

Quando um novo espaço de trabalho de frota é criado, um espaço de nome correspondente com um nome idêntico é gerado automaticamente no cluster local do Rancher.
Para que um usuário veja e implemente recursos da frota em um espaço de trabalho específico, ele precisa ter pelo menos as seguintes permissões:

* listar/obter o recurso de todo o cluster `+fleetworkspace+` no cluster local
* Permissões para criar recursos de frota (como `+bundles+`, `+gitrepos+`, ...) no namespace de apoio para o espaço de trabalho no cluster local.

Vamos conceder permissões para implantar recursos de frota nos espaços de trabalho de frota `+project1+` e `+project2+`:

ifeval::["{product}" == "fleet"]
* Para criar os espaços de trabalho de frota `+project1+` e `+project2+`, você pode fazer isso na usuário do Rancher https://ranchermanager.docs.rancher.com/integrations-in-rancher/fleet/overview#accessing-fleet-in-the-rancher-ui[interface do] ou usar os seguintes recursos YAML:
endif::[]

ifeval::["{product}" == "continuous-delivery"]

* Para criar os espaços de trabalho de frota `+project1+` e `+project2+`, você pode fazer isso na usuário do Rancher https://documentation.suse.com/cloudnative/rancher-manager/latest/en/integrations/fleet/overview.html#_accessing_suse_rancher_prime_continuous_delivery_in_the_rancher_ui[interface do] ou usar os seguintes recursos YAML:

[,yaml]
----
apiVersion: management.cattle.io/v3
kind: FleetWorkspace
metadata:
  name: project1
----

[,yaml]
----
apiVersion: management.cattle.io/v3
kind: FleetWorkspace
metadata:
  name: project2
----

* Crie um `+GlobalRole+` que conceda permissão para implementar recursos de frota nos espaços de trabalho de frota `+project1+` e `+project2+`:

[,yaml]
----
apiVersion: management.cattle.io/v3
kind: GlobalRole
metadata:
  name: fleet-projects1and2
namespacedRules:
  project1:
    - apiGroups:
        - fleet.cattle.io
      resources:
        - gitrepos
        - bundles
        - clusterregistrationtokens
        - gitreporestrictions
        - clusters
        - clustergroups
      verbs:
        - '*'
  project2:
    - apiGroups:
        - fleet.cattle.io
      resources:
        - gitrepos
        - bundles
        - clusterregistrationtokens
        - gitreporestrictions
        - clusters
        - clustergroups
      verbs:
        - '*'
rules:
  - apiGroups:
      - management.cattle.io
    resourceNames:
      - project1
      - project2
    resources:
      - fleetworkspaces
    verbs:
      - '*'
----

ifeval::["{product}" == "fleet"]
Atribua o `+GlobalRole+` a usuários ou grupos; mais informações podem ser encontradas nos https://ranchermanager.docs.rancher.com/how-to-guides/new-user-guides/authentication-permissions-and-global-configuration/manage-role-based-access-control-rbac/global-permissions#configuring-global-permissions-for-individual-users[documentos do] Rancher
endif::[]

ifeval::["{product}" == "continuous-delivery"]

Atribua o `+GlobalRole+` a usuários ou grupos; mais informações podem ser encontradas nos https://documentation.suse.com/cloudnative/rancher-manager/v2.12/en/rancher-admin/users/authn-and-authz/manage-role-based-access-control-rbac/global-permissions.html#_configuring_global_permissions_for_individual_users[documentos do] Rancher
endif::[]

O usuário agora tem acesso à guia `+Continuous Delivery+` no Rancher e pode implementar recursos nos espaços de trabalho `+project1+` e `+project2+`.

Para ter um ambiente bem organizado, cada espaço de trabalho deve ter seu próprio `+GlobalRole+` para ajudar na separação de tarefas e no isolamento exigido pelo cliente. Dessa forma, cada usuário pode ser atribuído a um ou mais `+GlobalRoles+`, dependendo das necessidades.

== Permitir acesso aos clusters

Isso pressupõe que todos os GitRepos criados por 'fleetuser' tenham o rótulo `+team: one+`. Diferentes rótulos podem ser usados para selecionar diferentes namespaces de cluster.

Em cada um dos namespaces do usuário, como administrador, crie um arquivo xref:explanations/namespaces.adoc#_cross_namespace_deployments[`+BundleNamespaceMapping+`].

[,yaml]
....
kind: BundleNamespaceMapping
apiVersion: fleet.cattle.io/v1alpha1
metadata:
  name: mapping
  namespace: project1

# Bundles to match by label.
# The labels are defined in the fleet.yaml # labels field or from the
# GitRepo metadata.labels field
bundleSelector:
  matchLabels:
    team: one
    # or target one repo
    #fleet.cattle.io/repo-name: simpleapp

# Namespaces, containing clusters, to match by label
namespaceSelector:
  matchLabels:
    kubernetes.io/metadata.name: fleet-default
    # the label is on the namespace
    #workspace: prod
....

A xref:how-tos-for-users/gitrepo-targets.adoc[seção`+target+` ] no recurso GitRepo pode ser usada para implantar apenas em um subconjunto dos clusters correspondentes.

== Restrição de acesso a clusters downstream

Os administradores podem restringir ainda mais os locatários criando um `+GitRepoRestriction+` em cada um de seus namespaces.

[,yaml]
....
kind: GitRepoRestriction
apiVersion: fleet.cattle.io/v1alpha1
metadata:
  name: restriction
  namespace: project1

allowedTargetNamespaces:
  - project1simpleapp
....

Isso negará a criação de recursos em todo o cluster, o que pode interferir em outros locatários, e limitará a implementação ao namespace "project1simpleapp".

== Um exemplo de recurso GitRepo

Um recurso GitRepo criado por um locatário, sem acesso de administrador, poderia ter a seguinte aparência:

[,yaml]
....
kind: GitRepo
apiVersion: fleet.cattle.io/v1alpha1
metadata:
  name: simpleapp
  namespace: project1
  labels:
    team: one

spec:
  repo: https://github.com/rancher/fleet-examples
  paths:
  - bundle-diffs

  targetNamespace: project1simpleapp

  # do not match the upstream/local cluster, won't work
  targets:
  - name: dev
    clusterSelector:
      matchLabels:
        env: dev
....

Isso inclui o rótulo `+team: one+` e o `+targetNamespace+` necessário.

Juntamente com o `+BundleNamespaceMapping+` anterior, ele teria como alvo todos os clusters com um rótulo `+env: dev+` no namespace 'fleet-default'.

[NOTE]
====

`+BundleNamespaceMappings+` não funcionam com clusters locais, portanto, certifique-se de não direcioná-los.
====

